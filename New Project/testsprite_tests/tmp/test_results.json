[
  {
    "projectId": "5b2a1122-e555-49ae-8f18-d5b06e482aa7",
    "testId": "848dd54c-33bf-48f2-8d0a-4461ae3de4b3",
    "userId": "b4a89488-00f1-70fd-91b8-1d57f527effa",
    "title": "TC001-initialize delta sync for a file",
    "description": "Test the /delta/init POST endpoint to verify that delta sync initialization creates the first snapshot with correct metadata and returns success.",
    "code": "import requests\nimport uuid\nimport json\n\nBASE_URL = \"http://localhost:5000\"\nTIMEOUT = 30\n\n# Use a placeholder JWT token for testing purposes\nJWT_TOKEN = \"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.fakepayload.fakesignature\"\n\ndef test_initialize_delta_sync_for_file():\n    # Prepare test data\n    project_id = str(uuid.uuid4())\n    file_id = f\"testfile-{uuid.uuid4()}.txt\"\n    user_id = str(uuid.uuid4())\n    initial_content = \"This is the initial file content.\\nLine 2 of the content.\\n\"\n\n    url = f\"{BASE_URL}/delta/init\"\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": JWT_TOKEN\n    }\n    payload = {\n        \"projectId\": project_id,\n        \"fileId\": file_id,\n        \"initialContent\": initial_content,\n        \"userId\": user_id\n    }\n\n    snapshot_id = None\n\n    try:\n        response = requests.post(url, headers=headers, json=payload, timeout=TIMEOUT)\n        assert response.status_code == 200, f\"Expected status code 200, got {response.status_code}\"\n\n        data = response.json()\n        assert \"success\" in data and data[\"success\"] is True, \"Initialization failed, success flag false or missing\"\n        assert \"snapshot\" in data and isinstance(data[\"snapshot\"], dict), \"Response lacks snapshot object\"\n\n        snapshot = data[\"snapshot\"]\n\n        # Validate snapshot metadata presence and basic fields\n        assert \"snapshotId\" in snapshot and isinstance(snapshot[\"snapshotId\"], str) and len(snapshot[\"snapshotId\"]) > 0, \"snapshotId missing or invalid\"\n        snapshot_id = snapshot[\"snapshotId\"]\n\n        assert snapshot.get(\"projectId\") == project_id, \"projectId mismatch in snapshot\"\n        assert snapshot.get(\"fileId\") == file_id, \"fileId mismatch in snapshot\"\n        if \"userId\" in snapshot:\n            assert snapshot[\"userId\"] == user_id, \"userId mismatch in snapshot\"\n        assert isinstance(snapshot.get(\"versionNumber\"), int) and snapshot.get(\"versionNumber\") == 1, \"versionNumber should be 1 for initial snapshot\"\n\n        assert snapshot.get(\"fullSnapshot\") == initial_content, \"fullSnapshot content does not match initial content\"\n\n        # Metadata checks\n        metadata = snapshot.get(\"metadata\")\n        assert isinstance(metadata, dict), \"Metadata missing or invalid\"\n        orig_size = metadata.get(\"originalSize\")\n        comp_size = metadata.get(\"compressedSize\")\n        comp_ratio = metadata.get(\"compressionRatio\")\n        lines_added = metadata.get(\"linesAdded\")\n        lines_removed = metadata.get(\"linesRemoved\")\n\n        assert isinstance(orig_size, int) and orig_size == len(initial_content), \"originalSize mismatch\"\n        assert isinstance(comp_size, int) and comp_size <= orig_size, \"compressedSize should be <= originalSize\"\n        assert isinstance(comp_ratio, (float, int)) and 0 <= comp_ratio <= 1, \"compressionRatio should be between 0 and 1\"\n        assert isinstance(lines_added, int) and lines_added >= 0, \"linesAdded should be non-negative integer\"\n        assert isinstance(lines_removed, int) and lines_removed == 0, \"linesRemoved should be 0 for initial snapshot\"\n\n        # Check createdAt datetime string existence\n        assert \"createdAt\" in snapshot and isinstance(snapshot[\"createdAt\"], str) and len(snapshot[\"createdAt\"]) > 0, \"createdAt missing or invalid\"\n\n    finally:\n        # Cleanup: delete snapshot if possible to not leave test data\n        if snapshot_id:\n            # Assuming there's a DELETE endpoint for snapshots (not specified in PRD),\n            # but since no delete is defined, skip deletion or extend if API supports it\n            pass\n\ntest_initialize_delta_sync_for_file()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 79, in <module>\n  File \"<string>\", line 34, in test_initialize_delta_sync_for_file\nAssertionError: Expected status code 200, got 401\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-11-01T23:55:16.285Z",
    "modified": "2025-11-01T23:56:14.213Z"
  },
  {
    "projectId": "5b2a1122-e555-49ae-8f18-d5b06e482aa7",
    "testId": "6b22981e-62e4-4bf8-900f-8fcc8dbba6a1",
    "userId": "b4a89488-00f1-70fd-91b8-1d57f527effa",
    "title": "TC002-create a new snapshot with delta compression",
    "description": "Test the /delta/snapshot POST endpoint to ensure new snapshots are created with delta compression, storing only incremental changes and returning the new version number.",
    "code": "import requests\nimport uuid\nimport hashlib\n\nBASE_URL = \"http://localhost:5000\"\nTIMEOUT = 30\n# Added Authorization header with dummy JWT token\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer dummy-jwt-token\"\n}\n\ndef test_create_new_snapshot_with_delta_compression():\n    # Prepare data for initialization (to create a new resource)\n    project_id = str(uuid.uuid4())\n    file_id = f\"test-file-{uuid.uuid4()}.txt\"\n    initial_content = \"Initial file content for delta sync testing.\\nLine 2.\\nLine 3.\"\n    user_id = str(uuid.uuid4())\n\n    init_payload = {\n        \"projectId\": project_id,\n        \"fileId\": file_id,\n        \"initialContent\": initial_content,\n        \"userId\": user_id\n    }\n\n    snapshot_id = None\n    try:\n        # Step 1: Initialize delta sync for a new file (creates first snapshot)\n        init_resp = requests.post(\n            f\"{BASE_URL}/delta/init\",\n            json=init_payload,\n            headers=HEADERS,\n            timeout=TIMEOUT\n        )\n        assert init_resp.status_code == 200, f\"Init request failed: {init_resp.text}\"\n        init_data = init_resp.json()\n        assert init_data.get(\"success\") is True, \"Delta init did not succeed\"\n        snapshot = init_data.get(\"snapshot\")\n        assert snapshot is not None, \"No snapshot returned in init response\"\n        snapshot_id = snapshot.get(\"snapshotId\")\n        assert snapshot_id is not None, \"Snapshot missing snapshotId in init response\"\n        # Save the first version content and version number\n        old_content = initial_content\n        old_version_number = snapshot.get(\"versionNumber\", 1)\n\n        # Prepare data for creating new snapshot with delta compression\n        # Modify content slightly\n        new_content = \"Initial file content for delta sync testing.\\nLine 2 modified.\\nLine 3.\\nAdded line 4.\"\n        message = \"Updated file with new changes\"\n        trigger = \"manual\"\n\n        snapshot_payload = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"content\": new_content,\n            \"oldContent\": old_content,\n            \"message\": message,\n            \"trigger\": trigger\n        }\n\n        # Step 2: Create a new snapshot with delta compression\n        snapshot_resp = requests.post(\n            f\"{BASE_URL}/delta/snapshot\",\n            json=snapshot_payload,\n            headers=HEADERS,\n            timeout=TIMEOUT\n        )\n        assert snapshot_resp.status_code == 200, f\"Snapshot creation failed: {snapshot_resp.text}\"\n        snapshot_data = snapshot_resp.json()\n        assert snapshot_data.get(\"success\") is True, \"Snapshot creation not successful\"\n\n        new_snapshot = snapshot_data.get(\"snapshot\")\n        version_number = snapshot_data.get(\"versionNumber\")\n\n        # Validate snapshot fields for delta compression\n        assert new_snapshot is not None, \"No snapshot data returned\"\n        assert \"delta\" in new_snapshot and new_snapshot[\"delta\"] is not None, \"Delta information missing in snapshot\"\n        delta = new_snapshot[\"delta\"]\n        assert \"data\" in delta and isinstance(delta[\"data\"], str) and len(delta[\"data\"]) > 0, \"Delta data missing or empty\"\n        assert delta.get(\"format\") == \"diff\", \"Delta format should be 'diff'\"\n\n        # Metadata validations\n        metadata = new_snapshot.get(\"metadata\")\n        assert metadata is not None, \"Metadata missing in snapshot\"\n        assert isinstance(metadata.get(\"originalSize\"), int) and metadata[\"originalSize\"] > 0, \"Invalid originalSize in metadata\"\n        assert isinstance(metadata.get(\"compressedSize\"), int) and metadata[\"compressedSize\"] > 0, \"Invalid compressedSize in metadata\"\n        # Compression ratio should be positive and <= 1 (typical compression ratio)\n        compression_ratio = metadata.get(\"compressionRatio\")\n        assert isinstance(compression_ratio, (float, int)) and 0 < compression_ratio <= 1, \"Invalid compressionRatio\"\n\n        # Version number should be incremented\n        assert isinstance(version_number, int), \"versionNumber missing or invalid\"\n        assert version_number > old_version_number, \"versionNumber did not increment\"\n\n        # Check checksum integrity (checksum is SHA256 of content)\n        checksum = new_snapshot.get(\"checksum\")\n        assert isinstance(checksum, str) and len(checksum) == 64, \"Invalid checksum format\"\n        calculated_checksum = hashlib.sha256(new_content.encode('utf-8')).hexdigest()\n        assert checksum == calculated_checksum, \"Checksum does not match content hash\"\n\n        # Trigger and message are as sent\n        assert new_snapshot.get(\"trigger\") == trigger, \"Trigger mismatch\"\n        assert new_snapshot.get(\"message\") == message, \"Message mismatch\"\n\n    finally:\n        # Cleanup: delete snapshots for the test file (assuming cleanup API exists)\n        # Note: The PRD does not specify a delete snapshot API; skipping if none available\n        pass\n\ntest_create_new_snapshot_with_delta_compression()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 111, in <module>\n  File \"<string>\", line 36, in test_create_new_snapshot_with_delta_compression\nAssertionError: Init request failed: {\"success\":false,\"message\":\"Invalid or expired token\",\"error\":\"Invalid or expired token\"}\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-11-01T23:55:16.292Z",
    "modified": "2025-11-01T23:56:17.483Z"
  },
  {
    "projectId": "5b2a1122-e555-49ae-8f18-d5b06e482aa7",
    "testId": "31cf3c46-b96f-441c-9eab-240e96935acb",
    "userId": "b4a89488-00f1-70fd-91b8-1d57f527effa",
    "title": "TC003-retrieve paginated version history for a file",
    "description": "Test the /delta/history/:fileId GET endpoint to verify retrieval of version history with pagination parameters limit and skip, returning correct snapshots and total count.",
    "code": "import requests\nimport uuid\nimport os\n\nBASE_URL = \"http://localhost:5000\"\nTIMEOUT = 30\n\n# You should set your JWT token as environment variable CODE_SYNC_JWT or replace below\nJWT_TOKEN = os.getenv(\"CODE_SYNC_JWT\", \"your_jwt_token_here\")\n\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {JWT_TOKEN}\"\n}\n\ndef test_retrieve_paginated_version_history_for_file():\n    project_id = str(uuid.uuid4())\n    file_id = str(uuid.uuid4())\n    user_id = str(uuid.uuid4())\n    initial_content = \"Initial content for version history test.\"\n\n    # Initialize delta sync for a new file to create snapshots for pagination test\n    init_payload = {\n        \"projectId\": project_id,\n        \"fileId\": file_id,\n        \"initialContent\": initial_content,\n        \"userId\": user_id\n    }\n\n    try:\n        # Create initial snapshot\n        init_response = requests.post(\n            f\"{BASE_URL}/delta/init\",\n            json=init_payload,\n            headers=HEADERS,\n            timeout=TIMEOUT\n        )\n        assert init_response.status_code == 200, f\"Init failed: {init_response.text}\"\n        init_data = init_response.json()\n        assert init_data.get(\"success\") is True\n        assert \"snapshot\" in init_data\n        prev_content = initial_content\n        # Create multiple snapshots to have version history for pagination\n        for i in range(1, 6):\n            new_content = prev_content + f\"\\nChange {i}\"\n            snapshot_payload = {\n                \"projectId\": project_id,\n                \"fileId\": file_id,\n                \"content\": new_content,\n                \"oldContent\": prev_content,\n                \"message\": f\"Commit {i}\",\n                \"trigger\": \"manual\"\n            }\n            snapshot_response = requests.post(\n                f\"{BASE_URL}/delta/snapshot\",\n                json=snapshot_payload,\n                headers=HEADERS,\n                timeout=TIMEOUT\n            )\n            assert snapshot_response.status_code == 200, f\"Snapshot creation failed: {snapshot_response.text}\"\n            snapshot_data = snapshot_response.json()\n            assert snapshot_data.get(\"success\") is True\n            assert \"snapshot\" in snapshot_data\n            assert isinstance(snapshot_data.get(\"versionNumber\"), int)\n            prev_content = new_content\n\n        # Test pagination: limit=3, skip=1\n        params = {\"limit\": 3, \"skip\": 1}\n        history_response = requests.get(\n            f\"{BASE_URL}/delta/history/{file_id}\",\n            headers=HEADERS,\n            params=params,\n            timeout=TIMEOUT\n        )\n        assert history_response.status_code == 200, f\"History retrieval failed: {history_response.text}\"\n        history_data = history_response.json()\n        assert history_data.get(\"success\") is True\n        assert isinstance(history_data.get(\"snapshots\"), list)\n        assert isinstance(history_data.get(\"total\"), int)\n        snapshots = history_data.get(\"snapshots\")\n        total = history_data.get(\"total\")\n\n        # Validate pagination logic\n        assert len(snapshots) <= params[\"limit\"]\n        assert total >= len(snapshots)\n\n        # Each snapshot should have required fields and fileId matching\n        for snapshot in snapshots:\n            assert snapshot.get(\"fileId\") == file_id\n            assert \"snapshotId\" in snapshot and isinstance(snapshot[\"snapshotId\"], str)\n            assert \"versionNumber\" in snapshot and isinstance(snapshot[\"versionNumber\"], int)\n            assert \"createdAt\" in snapshot\n\n    finally:\n        # Cleanup: Delete snapshots and file if API available (not described in PRD)\n        # Since no delete endpoint in PRD, skip actual cleanup or implement if API is known\n        pass\n\ntest_retrieve_paginated_version_history_for_file()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 99, in <module>\n  File \"<string>\", line 38, in test_retrieve_paginated_version_history_for_file\nAssertionError: Init failed: {\"success\":false,\"message\":\"Invalid or expired token\",\"error\":\"Invalid or expired token\"}\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-11-01T23:55:16.297Z",
    "modified": "2025-11-01T23:56:17.481Z"
  },
  {
    "projectId": "5b2a1122-e555-49ae-8f18-d5b06e482aa7",
    "testId": "9d6a6072-e334-47d3-96e8-e139d701ce20",
    "userId": "b4a89488-00f1-70fd-91b8-1d57f527effa",
    "title": "TC004-rollback file to a specific snapshot version",
    "description": "Test the /delta/rollback POST endpoint to ensure rollback restores file content exactly matching the chosen snapshot version and returns the snapshot details.",
    "code": "import requests\nimport uuid\n\nBASE_URL = \"http://localhost:5000\"\nTIMEOUT = 30\n# Replace 'your_valid_jwt_token_here' with an actual valid JWT token\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer your_valid_jwt_token_here\"\n}\n\ndef test_rollback_file_to_specific_snapshot_version():\n    # Prepare unique ids and initial content\n    project_id = str(uuid.uuid4())\n    file_id = f\"testfile_{uuid.uuid4()}.txt\"\n    user_id = str(uuid.uuid4())\n\n    initial_content = \"This is the initial content.\\nLine 2.\\nLine 3.\"\n    updated_content = \"This is the updated content.\\nLine 2 modified.\\nLine 3.\"\n\n    created_snapshot_ids = []\n\n    try:\n        # Step 1: Initialize delta sync for a new file (create first snapshot)\n        init_payload = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"initialContent\": initial_content,\n            \"userId\": user_id\n        }\n        r_init = requests.post(f\"{BASE_URL}/delta/init\", json=init_payload, headers=HEADERS, timeout=TIMEOUT)\n        assert r_init.status_code == 200, f\"Delta init failed: {r_init.text}\"\n        init_json = r_init.json()\n        assert init_json.get(\"success\") is True, \"Init response success flag is False\"\n        snapshot1 = init_json.get(\"snapshot\")\n        assert snapshot1 is not None, \"No snapshot returned from init\"\n        snapshot1_id = snapshot1.get(\"snapshotId\")\n        assert snapshot1_id, \"Init snapshot missing snapshotId\"\n        created_snapshot_ids.append(snapshot1_id)\n\n        # Step 2: Create a new snapshot with updated content (delta compression)\n        snapshot_payload = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"content\": updated_content,\n            \"oldContent\": initial_content,\n            \"message\": \"Updated content for test\",\n            \"trigger\": \"manual\"\n        }\n        r_snapshot = requests.post(f\"{BASE_URL}/delta/snapshot\", json=snapshot_payload, headers=HEADERS, timeout=TIMEOUT)\n        assert r_snapshot.status_code == 200, f\"Create snapshot failed: {r_snapshot.text}\"\n        snap_json = r_snapshot.json()\n        assert snap_json.get(\"success\") is True, \"Snapshot creation success flag is False\"\n        snapshot2 = snap_json.get(\"snapshot\")\n        assert snapshot2 is not None, \"No snapshot returned from create snapshot\"\n        snapshot2_id = snapshot2.get(\"snapshotId\")\n        assert snapshot2_id, \"Snapshot creation missing snapshotId\"\n        created_snapshot_ids.append(snapshot2_id)\n\n        # Step 3: Rollback file to the first snapshot version (initial)\n        rollback_payload = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"snapshotId\": snapshot1_id,\n            \"userId\": user_id\n        }\n        r_rollback = requests.post(f\"{BASE_URL}/delta/rollback\", json=rollback_payload, headers=HEADERS, timeout=TIMEOUT)\n        assert r_rollback.status_code == 200, f\"Rollback failed: {r_rollback.text}\"\n        rollback_json = r_rollback.json()\n        assert rollback_json.get(\"success\") is True, \"Rollback success flag is False\"\n        restored_content = rollback_json.get(\"content\")\n        rollback_snapshot = rollback_json.get(\"snapshot\")\n        assert rollback_snapshot is not None, \"Rollback response missing snapshot details\"\n        assert rollback_snapshot.get(\"snapshotId\") == snapshot1_id, \"Rollback snapshotId does not match requested\"\n        # Content restored should exactly match initial content\n        assert restored_content == initial_content, \"Restored content does not match initial snapshot content\"\n\n        # Step 4: Rollback file to the second snapshot version (updated)\n        rollback_payload2 = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"snapshotId\": snapshot2_id,\n            \"userId\": user_id\n        }\n        r_rollback2 = requests.post(f\"{BASE_URL}/delta/rollback\", json=rollback_payload2, headers=HEADERS, timeout=TIMEOUT)\n        assert r_rollback2.status_code == 200, f\"Rollback to second snapshot failed: {r_rollback2.text}\"\n        rollback_json2 = r_rollback2.json()\n        assert rollback_json2.get(\"success\") is True, \"Rollback to second snapshot success flag is False\"\n        restored_content2 = rollback_json2.get(\"content\")\n        rollback_snapshot2 = rollback_json2.get(\"snapshot\")\n        assert rollback_snapshot2 is not None, \"Rollback to second snapshot missing snapshot details\"\n        assert rollback_snapshot2.get(\"snapshotId\") == snapshot2_id, \"Rollback second snapshotId does not match requested\"\n        # Content restored should exactly match updated content\n        assert restored_content2 == updated_content, \"Restored content does not match updated snapshot content\"\n\n    finally:\n        # Cleanup: If there was an API to delete snapshots or files, call here.\n        # As no delete endpoint described, no cleanup of snapshots is done.\n        pass\n\ntest_rollback_file_to_specific_snapshot_version()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 101, in <module>\n  File \"<string>\", line 32, in test_rollback_file_to_specific_snapshot_version\nAssertionError: Delta init failed: {\"success\":false,\"message\":\"Invalid or expired token\",\"error\":\"Invalid or expired token\"}\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-11-01T23:55:16.302Z",
    "modified": "2025-11-01T23:56:35.304Z"
  },
  {
    "projectId": "5b2a1122-e555-49ae-8f18-d5b06e482aa7",
    "testId": "c2aceef3-4529-4594-b4aa-685c3e8eaec1",
    "userId": "b4a89488-00f1-70fd-91b8-1d57f527effa",
    "title": "TC005-compare two snapshots for differences",
    "description": "Test the /delta/compare POST endpoint to verify comparison of two snapshots returns accurate unified diff format, lines added, and lines removed.",
    "code": "import requests\nimport uuid\n\nBASE_URL = \"http://localhost:5000\"\nTIMEOUT = 30\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer <token>\"\n}\n\ndef test_TC005_compare_two_snapshots_for_differences():\n    project_id = str(uuid.uuid4())\n    file_id = \"test/file/path_\" + str(uuid.uuid4())\n    user_id = str(uuid.uuid4())\n\n    initial_content = \"line1\\nline2\\nline3\\nline4\\n\"\n    modified_content = \"line1\\nline2 modified\\nline3\\nline5 added\\n\"\n\n    snapshot_ids = []\n\n    try:\n        # Initialize delta sync and create the first snapshot\n        init_payload = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"initialContent\": initial_content,\n            \"userId\": user_id\n        }\n        init_resp = requests.post(\n            f\"{BASE_URL}/delta/init\",\n            json=init_payload,\n            headers=HEADERS,\n            timeout=TIMEOUT\n        )\n        assert init_resp.status_code == 200, f\"Init failed: {init_resp.text}\"\n        init_data = init_resp.json()\n        assert init_data.get(\"success\") is True, f\"Init success false: {init_data}\"\n        snapshot1 = init_data.get(\"snapshot\")\n        assert snapshot1 and \"snapshotId\" in snapshot1, \"No snapshotId in init response\"\n        snapshot_ids.append(snapshot1[\"snapshotId\"])\n\n        # Create a new snapshot with modified content and delta compression\n        snapshot_payload = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"content\": modified_content,\n            \"oldContent\": initial_content,\n            \"message\": \"Modified lines 2 and 4\",\n            \"trigger\": \"manual\"\n        }\n        snapshot_resp = requests.post(\n            f\"{BASE_URL}/delta/snapshot\",\n            json=snapshot_payload,\n            headers=HEADERS,\n            timeout=TIMEOUT\n        )\n        assert snapshot_resp.status_code == 200, f\"Snapshot creation failed: {snapshot_resp.text}\"\n        snapshot_data = snapshot_resp.json()\n        assert snapshot_data.get(\"success\") is True, f\"Snapshot creation failed: {snapshot_data}\"\n        snapshot2 = snapshot_data.get(\"snapshot\")\n        assert snapshot2 and \"snapshotId\" in snapshot2, \"No snapshotId in snapshot creation response\"\n        snapshot_ids.append(snapshot2[\"snapshotId\"])\n\n        # Call the compare endpoint with the two snapshots\n        compare_payload = {\n            \"fileId\": file_id,\n            \"snapshotId1\": snapshot_ids[0],\n            \"snapshotId2\": snapshot_ids[1]\n        }\n        compare_resp = requests.post(\n            f\"{BASE_URL}/delta/compare\",\n            json=compare_payload,\n            headers=HEADERS,\n            timeout=TIMEOUT\n        )\n        assert compare_resp.status_code == 200, f\"Compare request failed: {compare_resp.text}\"\n        compare_data = compare_resp.json()\n        assert compare_data.get(\"success\") is True, f\"Compare success false: {compare_data}\"\n        diff = compare_data.get(\"diff\")\n        lines_added = compare_data.get(\"linesAdded\")\n        lines_removed = compare_data.get(\"linesRemoved\")\n\n        assert isinstance(diff, str) and diff, \"Invalid or empty diff string\"\n        assert isinstance(lines_added, int) and lines_added >= 0, \"Invalid linesAdded\"\n        assert isinstance(lines_removed, int) and lines_removed >= 0, \"Invalid linesRemoved\"\n\n        # Basic content check in unified diff (should contain line changes)\n        assert (\"-line2\" in diff or \"-line2\\n\" in diff or \"-line2 modified\" not in diff), \"Diff missing expected line removal\"\n        assert (\"+line2 modified\" in diff), \"Diff missing expected line addition\"\n        assert (\"+line5 added\" in diff), \"Diff missing expected added line\"\n        assert (\"-line4\" in diff or \"-line4\\n\" in diff), \"Diff missing expected removed line\"\n        assert lines_added > 0 or lines_removed > 0, \"No lines added or removed detected\"\n\n    finally:\n        # Cleanup: Rollback or delete snapshots if delete API existed, but only snapshot creation init is primarily reversible.\n        # Since no delete endpoint specified in PRD, skip cleanup or could consider rollback if applicable.\n        # For safety, no cleanup as per given endpoints to avoid data loss.\n        pass\n\ntest_TC005_compare_two_snapshots_for_differences()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 100, in <module>\n  File \"<string>\", line 35, in test_TC005_compare_two_snapshots_for_differences\nAssertionError: Init failed: {\"success\":false,\"message\":\"Invalid or expired token\",\"error\":\"Invalid or expired token\"}\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-11-01T23:55:16.306Z",
    "modified": "2025-11-01T23:56:17.491Z"
  },
  {
    "projectId": "5b2a1122-e555-49ae-8f18-d5b06e482aa7",
    "testId": "f751eed7-a97d-4238-929c-8411e765c612",
    "userId": "b4a89488-00f1-70fd-91b8-1d57f527effa",
    "title": "TC006-get snapshot statistics for a file",
    "description": "Test the /delta/stats/:fileId GET endpoint to verify retrieval of snapshot statistics including total snapshots, storage usage, average compression ratio, and timestamps.",
    "code": "import requests\nimport uuid\nimport time\n\nBASE_URL = \"http://localhost:5000\"\nTIMEOUT = 30\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer your_jwt_token_here\"\n}\n\ndef test_get_snapshot_statistics_for_a_file():\n    project_id = str(uuid.uuid4())\n    file_id = str(uuid.uuid4())\n    user_id = str(uuid.uuid4())\n    initial_content = \"print('Initial content for snapshot statistics test')\"\n\n    init_payload = {\n        \"projectId\": project_id,\n        \"fileId\": file_id,\n        \"initialContent\": initial_content,\n        \"userId\": user_id\n    }\n\n    # Create initial snapshot by initializing delta sync\n    init_resp = requests.post(f\"{BASE_URL}/delta/init\", json=init_payload, headers=HEADERS, timeout=TIMEOUT)\n    assert init_resp.status_code == 200, f\"Init snapshot failed: {init_resp.text}\"\n    init_data = init_resp.json()\n    assert init_data.get(\"success\") is True\n    assert \"snapshot\" in init_data and isinstance(init_data[\"snapshot\"], dict)\n    snapshot_ids = [init_data[\"snapshot\"][\"snapshotId\"]]\n\n    # Create a couple more snapshots to test statistics\n    last_content = initial_content\n    for i in range(2):\n        new_content = last_content + f\"\\n# Change {i+1}\"\n        snapshot_payload = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"content\": new_content,\n            \"oldContent\": last_content,\n            \"message\": f\"Snapshot {i+2}\",\n            \"trigger\": \"manual\"\n        }\n        snap_resp = requests.post(f\"{BASE_URL}/delta/snapshot\", json=snapshot_payload, headers=HEADERS, timeout=TIMEOUT)\n        assert snap_resp.status_code == 200, f\"Create snapshot failed: {snap_resp.text}\"\n        snap_data = snap_resp.json()\n        assert snap_data.get(\"success\") is True\n        assert \"snapshot\" in snap_data and isinstance(snap_data[\"snapshot\"], dict)\n        snapshot_ids.append(snap_data[\"snapshot\"][\"snapshotId\"])\n        last_content = new_content\n\n    try:\n        # Request snapshot statistics for the file\n        stats_resp = requests.get(f\"{BASE_URL}/delta/stats/{file_id}\", headers=HEADERS, timeout=TIMEOUT)\n        assert stats_resp.status_code == 200, f\"Get stats failed: {stats_resp.text}\"\n        stats_data = stats_resp.json()\n\n        assert stats_data.get(\"success\") is True\n        stats = stats_data.get(\"stats\")\n        assert isinstance(stats, dict)\n\n        # Validate expected statistics fields presence and types\n        assert \"totalSnapshots\" in stats and isinstance(stats[\"totalSnapshots\"], int) and stats[\"totalSnapshots\"] >= 3\n        assert \"totalSize\" in stats and isinstance(stats[\"totalSize\"], int) and stats[\"totalSize\"] > 0\n        assert \"avgCompressionRatio\" in stats and (isinstance(stats[\"avgCompressionRatio\"], float) or isinstance(stats[\"avgCompressionRatio\"], int))\n        assert \"oldestSnapshot\" in stats and isinstance(stats[\"oldestSnapshot\"], str)\n        assert \"newestSnapshot\" in stats and isinstance(stats[\"newestSnapshot\"], str)\n\n        # Validate ISO datetime format for timestamps (basic check)\n        time.strptime(stats[\"oldestSnapshot\"][:19], \"%Y-%m-%dT%H:%M:%S\")\n        time.strptime(stats[\"newestSnapshot\"][:19], \"%Y-%m-%dT%H:%M:%S\")\n\n    finally:\n        # Cleanup: Delete all created snapshots if API to delete snapshots is available\n        # No explicit delete snapshot endpoint defined in PRD, so skip cleanup here.\n        pass\n\ntest_get_snapshot_statistics_for_a_file()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 79, in <module>\n  File \"<string>\", line 27, in test_get_snapshot_statistics_for_a_file\nAssertionError: Init snapshot failed: {\"success\":false,\"message\":\"Invalid or expired token\",\"error\":\"Invalid or expired token\"}\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-11-01T23:55:16.312Z",
    "modified": "2025-11-01T23:56:14.215Z"
  },
  {
    "projectId": "5b2a1122-e555-49ae-8f18-d5b06e482aa7",
    "testId": "583045f8-9499-4869-937a-3d3e3d233913",
    "userId": "b4a89488-00f1-70fd-91b8-1d57f527effa",
    "title": "TC007-cleanup old snapshots beyond retention period",
    "description": "Test the /delta/cleanup/:fileId POST endpoint to ensure snapshots older than specified daysToKeep are deleted and the deleted count is returned.",
    "code": "import requests\nimport uuid\nimport time\n\nBASE_URL = \"http://localhost:5000\"\nTOKEN = \"your_jwt_token_here\"\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {TOKEN}\"\n}\nTIMEOUT = 30\n\ndef test_cleanup_old_snapshots_beyond_retention_period():\n    project_id = str(uuid.uuid4())\n    file_id = f\"testfile-{uuid.uuid4()}\"\n    user_id = str(uuid.uuid4())\n\n    init_payload = {\n        \"projectId\": project_id,\n        \"fileId\": file_id,\n        \"initialContent\": \"Initial content of the file\",\n        \"userId\": user_id\n    }\n\n    # Initialize a delta sync for the file to create the first snapshot\n    try:\n        init_resp = requests.post(f\"{BASE_URL}/delta/init\", json=init_payload, headers=HEADERS, timeout=TIMEOUT)\n        assert init_resp.status_code == 200, f\"Init failed with status {init_resp.status_code}\"\n        init_data = init_resp.json()\n        assert init_data.get(\"success\") is True, \"Init success flag false\"\n        first_snapshot = init_data.get(\"snapshot\")\n        assert first_snapshot is not None, \"No snapshot returned on init\"\n\n        # Create multiple snapshots with different createdAt to simulate old snapshots\n        old_snapshots = []\n        for i in range(3):\n            content = f\"File content version {i+2}\"\n            snapshot_payload = {\n                \"projectId\": project_id,\n                \"fileId\": file_id,\n                \"content\": content,\n                \"oldContent\": \"Initial content of the file\" if i == 0 else f\"File content version {i+1}\",\n                \"message\": f\"Snapshot {i+2}\",\n                \"trigger\": \"manual\"\n            }\n\n            snap_resp = requests.post(f\"{BASE_URL}/delta/snapshot\", json=snapshot_payload, headers=HEADERS, timeout=TIMEOUT)\n            assert snap_resp.status_code == 200, f\"Snapshot creation failed with status {snap_resp.status_code}\"\n            snap_data = snap_resp.json()\n            assert snap_data.get(\"success\") is True, \"Snapshot creation success false\"\n            snapshot = snap_data.get(\"snapshot\")\n            assert snapshot is not None, \"No snapshot returned on creation\"\n            old_snapshots.append(snapshot)\n\n        # Artificially simulate snapshots older than retention by patching their creation date if possible\n        # Since no direct API is given, assume the test environment auto-sets createdAt\n        # We proceed to call cleanup with daysToKeep=0 to delete all old snapshots except the newest\n        days_to_keep = 0\n\n        cleanup_resp = requests.post(f\"{BASE_URL}/delta/cleanup/{file_id}\", \n                                     json={\"daysToKeep\": days_to_keep}, headers=HEADERS, timeout=TIMEOUT)\n        assert cleanup_resp.status_code == 200, f\"Cleanup failed with status {cleanup_resp.status_code}\"\n        cleanup_data = cleanup_resp.json()\n        assert cleanup_data.get(\"success\") is True, \"Cleanup success false\"\n        deleted_count = cleanup_data.get(\"deletedCount\")\n        assert isinstance(deleted_count, int), \"deletedCount is not integer\"\n        assert deleted_count > 0, \"No snapshots deleted despite daysToKeep=0\"\n\n    finally:\n        # Cleanup: delete all snapshots and the file if API available\n        # No delete endpoint provided in PRD, so cleanup not implemented here.\n        pass\n\ntest_cleanup_old_snapshots_beyond_retention_period()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 74, in <module>\n  File \"<string>\", line 28, in test_cleanup_old_snapshots_beyond_retention_period\nAssertionError: Init failed with status 401\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-11-01T23:55:16.316Z",
    "modified": "2025-11-01T23:56:30.516Z"
  },
  {
    "projectId": "5b2a1122-e555-49ae-8f18-d5b06e482aa7",
    "testId": "1bf8b9f5-8a35-4094-a5dd-892649152822",
    "userId": "b4a89488-00f1-70fd-91b8-1d57f527effa",
    "title": "TC008-get file content at a specific version",
    "description": "Test the /delta/content/:fileId GET endpoint to verify reconstruction and retrieval of file content at a specified version number or latest if not specified.",
    "code": "import requests\nimport uuid\n\nBASE_URL = \"http://localhost:5000\"\nTIMEOUT = 30\nJWT_TOKEN = \"Bearer your_valid_jwt_token_here\"\nHEADERS = {\"Content-Type\": \"application/json\", \"Authorization\": JWT_TOKEN}\n\ndef test_get_file_content_at_specific_version():\n    # Setup: Initialize delta sync for a new file with an initial snapshot\n    project_id = str(uuid.uuid4())\n    file_id = str(uuid.uuid4())\n    user_id = str(uuid.uuid4())\n    initial_content = \"Line1\\nLine2\\nLine3\\n\"\n    init_payload = {\n        \"projectId\": project_id,\n        \"fileId\": file_id,\n        \"initialContent\": initial_content,\n        \"userId\": user_id\n    }\n\n    snapshot_ids = []\n    version_numbers = []\n    try:\n        # 1) Initialize delta sync to create first snapshot\n        r_init = requests.post(f\"{BASE_URL}/delta/init\", json=init_payload, headers=HEADERS, timeout=TIMEOUT)\n        r_init.raise_for_status()\n        init_response = r_init.json()\n        assert init_response.get(\"success\") is True\n        snapshot = init_response.get(\"snapshot\")\n        assert snapshot is not None\n        assert snapshot.get(\"versionNumber\") == 1\n        assert snapshot.get(\"fileId\") == file_id\n        snapshot_ids.append(snapshot.get(\"snapshotId\"))\n        version_numbers.append(snapshot.get(\"versionNumber\"))\n        current_content = initial_content\n\n        # 2) Create one or two more snapshots with incremental changes\n        # First update\n        new_content_v2 = \"Line1\\nLine 2 modified\\nLine3\\nLine4 added\\n\"\n        snapshot_payload_v2 = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"content\": new_content_v2,\n            \"oldContent\": current_content,\n            \"message\": \"Update v2\",\n            \"trigger\": \"manual\"\n        }\n        r_snap2 = requests.post(f\"{BASE_URL}/delta/snapshot\", json=snapshot_payload_v2, headers=HEADERS, timeout=TIMEOUT)\n        r_snap2.raise_for_status()\n        snap2_response = r_snap2.json()\n        assert snap2_response.get(\"success\") is True\n        snap2 = snap2_response.get(\"snapshot\")\n        assert snap2 is not None\n        snapshot_ids.append(snap2.get(\"snapshotId\"))\n        version_numbers.append(snap2_response.get(\"versionNumber\"))\n        current_content = new_content_v2\n\n        # Second update\n        new_content_v3 = \"Line0 added\\nLine1\\nLine 2 modified\\nLine3\\nLine4 added\\n\"\n        snapshot_payload_v3 = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"content\": new_content_v3,\n            \"oldContent\": current_content,\n            \"message\": \"Update v3\",\n            \"trigger\": \"manual\"\n        }\n        r_snap3 = requests.post(f\"{BASE_URL}/delta/snapshot\", json=snapshot_payload_v3, headers=HEADERS, timeout=TIMEOUT)\n        r_snap3.raise_for_status()\n        snap3_response = r_snap3.json()\n        assert snap3_response.get(\"success\") is True\n        snap3 = snap3_response.get(\"snapshot\")\n        assert snap3 is not None\n        snapshot_ids.append(snap3.get(\"snapshotId\"))\n        version_numbers.append(snap3_response.get(\"versionNumber\"))\n        current_content = new_content_v3\n\n        # 3) Test GET /delta/content/:fileId for specific versions\n\n        # Test retrieving version 1 content\n        r_content_v1 = requests.get(f\"{BASE_URL}/delta/content/{file_id}\", \n                                   params={\"version\": 1}, headers=HEADERS, timeout=TIMEOUT)\n        r_content_v1.raise_for_status()\n        content_v1 = r_content_v1.json()\n        assert content_v1.get(\"success\") is True\n        assert content_v1.get(\"versionNumber\") == 1\n        assert \"Line1\\nLine2\\nLine3\\n\" == content_v1.get(\"content\")\n\n        # Test retrieving version 2 content\n        r_content_v2 = requests.get(f\"{BASE_URL}/delta/content/{file_id}\", \n                                   params={\"version\": 2}, headers=HEADERS, timeout=TIMEOUT)\n        r_content_v2.raise_for_status()\n        content_v2 = r_content_v2.json()\n        assert content_v2.get(\"success\") is True\n        assert content_v2.get(\"versionNumber\") == 2\n        assert \"Line1\\nLine 2 modified\\nLine3\\nLine4 added\\n\" == content_v2.get(\"content\")\n\n        # Test retrieving version 3 content\n        r_content_v3 = requests.get(f\"{BASE_URL}/delta/content/{file_id}\", \n                                   params={\"version\": 3}, headers=HEADERS, timeout=TIMEOUT)\n        r_content_v3.raise_for_status()\n        content_v3 = r_content_v3.json()\n        assert content_v3.get(\"success\") is True\n        assert content_v3.get(\"versionNumber\") == 3\n        assert \"Line0 added\\nLine1\\nLine 2 modified\\nLine3\\nLine4 added\\n\" == content_v3.get(\"content\")\n\n        # Test retrieving content latest version without specifying version param\n        r_content_latest = requests.get(f\"{BASE_URL}/delta/content/{file_id}\", headers=HEADERS, timeout=TIMEOUT)\n        r_content_latest.raise_for_status()\n        content_latest = r_content_latest.json()\n        assert content_latest.get(\"success\") is True\n        assert content_latest.get(\"versionNumber\") == 3\n        assert \"Line0 added\\nLine1\\nLine 2 modified\\nLine3\\nLine4 added\\n\" == content_latest.get(\"content\")\n\n        # 4) Negative test: Request non-existent version number (e.g., 999)\n        r_content_invalid = requests.get(f\"{BASE_URL}/delta/content/{file_id}\", \n                                         params={\"version\": 999}, headers=HEADERS, timeout=TIMEOUT)\n        # The API might respond with 400 or 404 for invalid version - handle either\n        if r_content_invalid.status_code == 200:\n            resp = r_content_invalid.json()\n            # success likely false or content empty\n            assert resp.get(\"success\") is False or resp.get(\"content\") is None or resp.get(\"content\") == \"\"\n        else:\n            assert r_content_invalid.status_code in (400, 404)\n\n    finally:\n        # Cleanup: No direct delete API specified; if available, implement here.\n        # If no cleanup API, test environment should handle data persistence.\n        pass\n\ntest_get_file_content_at_specific_version()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 132, in <module>\n  File \"<string>\", line 27, in test_get_file_content_at_specific_version\n  File \"/var/task/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: http://localhost:5000/delta/init\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-11-01T23:55:16.321Z",
    "modified": "2025-11-01T23:56:58.162Z"
  },
  {
    "projectId": "5b2a1122-e555-49ae-8f18-d5b06e482aa7",
    "testId": "4c0fa158-a19f-499d-b077-c00072d5162a",
    "userId": "b4a89488-00f1-70fd-91b8-1d57f527effa",
    "title": "TC009-get all delta changes since a given version",
    "description": "Test the /delta/deltas-since/:fileId GET endpoint to ensure retrieval of all delta changes since the specified version number, returning an array of delta snapshots.",
    "code": "import requests\nimport uuid\n\nBASE_URL = \"http://localhost:5000\"\nTIMEOUT = 30\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer <VALID_JWT_TOKEN>\"\n}\n\ndef test_get_all_deltas_since_version():\n    # Setup: Initialize delta sync for a new file to create initial snapshot\n    project_id = str(uuid.uuid4())\n    file_id = str(uuid.uuid4())\n    user_id = str(uuid.uuid4())\n    initial_content = \"Initial content line 1\\nInitial content line 2\\n\"\n    init_payload = {\n        \"projectId\": project_id,\n        \"fileId\": file_id,\n        \"initialContent\": initial_content,\n        \"userId\": user_id\n    }\n\n    try:\n        init_resp = requests.post(f\"{BASE_URL}/delta/init\", json=init_payload, headers=HEADERS, timeout=TIMEOUT)\n        assert init_resp.status_code == 200, f\"Init failed with status {init_resp.status_code}\"\n        init_json = init_resp.json()\n        assert init_json.get(\"success\") is True\n        snapshot = init_json.get(\"snapshot\")\n        assert snapshot is not None\n        base_version = snapshot.get(\"versionNumber\")\n        assert isinstance(base_version, int)\n        assert base_version == 1\n\n        # Create another snapshot with changes (delta)\n        updated_content = initial_content + \"Added line 3\\n\"\n        snapshot_payload = {\n            \"projectId\": project_id,\n            \"fileId\": file_id,\n            \"content\": updated_content,\n            \"oldContent\": initial_content,\n            \"message\": \"Added line 3\",\n            \"trigger\": \"manual\"\n        }\n        snap_resp = requests.post(f\"{BASE_URL}/delta/snapshot\", json=snapshot_payload, headers=HEADERS, timeout=TIMEOUT)\n        assert snap_resp.status_code == 200, f\"Snapshot creation failed with status {snap_resp.status_code}\"\n        snap_json = snap_resp.json()\n        assert snap_json.get(\"success\") is True\n        new_version = snap_json.get(\"versionNumber\")\n        assert isinstance(new_version, int)\n        assert new_version > base_version\n\n        # Test: get all delta changes since base_version\n        params = {\"version\": base_version}\n        deltas_resp = requests.get(f\"{BASE_URL}/delta/deltas-since/{file_id}\", headers=HEADERS, params=params, timeout=TIMEOUT)\n        assert deltas_resp.status_code == 200, f\"Deltas retrieval failed with status {deltas_resp.status_code}\"\n        deltas_json = deltas_resp.json()\n        assert deltas_json.get(\"success\") is True\n        deltas = deltas_json.get(\"deltas\")\n        assert isinstance(deltas, list)\n        assert any(d.get(\"versionNumber\", 0) > base_version for d in deltas)\n\n        # Validate each delta has required properties\n        for delta in deltas:\n            assert \"snapshotId\" in delta and isinstance(delta[\"snapshotId\"], str)\n            assert \"versionNumber\" in delta and isinstance(delta[\"versionNumber\"], int)\n            assert \"fileId\" in delta and delta[\"fileId\"] == file_id\n            # Optional but recommended fields to check\n            assert \"delta\" in delta and isinstance(delta[\"delta\"], dict)\n            assert \"createdAt\" in delta\n    finally:\n        # Cleanup: no explicit delete endpoint is described, so skipping\n        # In a real environment, cleanup of test data would be here if API supported it\n        pass\n\ntest_get_all_deltas_since_version()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 76, in <module>\n  File \"<string>\", line 26, in test_get_all_deltas_since_version\nAssertionError: Init failed with status 401\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-11-01T23:55:16.326Z",
    "modified": "2025-11-01T23:56:37.757Z"
  }
]
